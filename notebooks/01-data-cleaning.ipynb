{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68c319a7",
   "metadata": {},
   "source": [
    "# Step 1 — Data Cleaning & Preprocessing\n",
    "\n",
    "This notebook performs initial data cleaning for the Telco Customer Churn dataset. It will:\n",
    "\n",
    "- Inspect the dataset for missing values and incorrect dtypes\n",
    "- Clean the `TotalCharges` column (common issue: loaded as object)\n",
    "- Apply a small, explicit missing-value policy (drop or impute based on fraction)\n",
    "- Encode categorical variables (one-hot for multi-class, keep binary as 0/1)\n",
    "- Save a cleaned CSV to `data/cleaned_telco_churn.csv`\n",
    "\n",
    "Checklist:\n",
    "- [ ] Load `WA_Fn-UseC_-Telco-Customer-Churn.csv`\n",
    "- [ ] Inspect for missing values and bad dtypes\n",
    "- [ ] Fix `TotalCharges` dtype and handle resulting NaNs\n",
    "- [ ] Encode categorical variables\n",
    "- [ ] Save cleaned dataset for modeling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bfefb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "\n",
    "pd.set_option('display.max_columns', 80)\n",
    "pd.set_option('display.width', 180)\n",
    "\n",
    "# Load dataset (adjust path if needed)\n",
    "csv_path = Path('..') / 'WA_Fn-UseC_-Telco-Customer-Churn.csv'  # notebook lives in notebooks/\n",
    "df = pd.read_csv(csv_path)\n",
    "print('Loaded', csv_path)\n",
    "print('Shape:', df.shape)\n",
    "df.head()\n",
    "\n",
    "# Quick structure check and missing values\n",
    "df.info()\n",
    "print('\\nMissing values per column:')\n",
    "print(df.isnull().sum())\n",
    "print('\\nBlank-string counts (object cols may contain spaces):')\n",
    "for c in df.select_dtypes(include=['object']).columns:\n",
    "    blanks = (df[c].astype(str).str.strip() == '').sum()\n",
    "    if blanks > 0:\n",
    "        print(f'{c}: {blanks} blank-like values')\n",
    "\n",
    "# TotalCharges is frequently stored as object due to blank strings. Convert to numeric.\n",
    "print('Before conversion dtype:', df['TotalCharges'].dtype)\n",
    "# coerce errors to NaN so we can count/fix them\n",
    "df['TotalCharges'] = pd.to_numeric(df['TotalCharges'], errors='coerce')\n",
    "print('After conversion dtype:', df['TotalCharges'].dtype)\n",
    "num_missing_total = df['TotalCharges'].isna().sum()\n",
    "print('TotalCharges NaNs:', num_missing_total, 'of', len(df), f'({num_missing_total/len(df):.2%})')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1152b5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decide strategy for missing TotalCharges: drop if very few, otherwise impute with median.\n",
    "missing_ratio = df['TotalCharges'].isna().mean()\n",
    "if missing_ratio == 0:\n",
    "    print('No missing TotalCharges — nothing to do')\n",
    "elif missing_ratio <= 0.05:\n",
    "    print('Missing fraction <=5%: dropping rows with missing TotalCharges')\n",
    "    df = df[~df['TotalCharges'].isna()].copy()\n",
    "else:\n",
    "    med = df['TotalCharges'].median()\n",
    "    print(f'Missing fraction >5%: imputing TotalCharges with median = {med:.2f}')\n",
    "    df['TotalCharges'] = df['TotalCharges'].fillna(med)\n",
    "\n",
    "print('New shape after TotalCharges handling:', df.shape)\n",
    "\n",
    "# Trim whitespace in object columns and normalize common binary columns\n",
    "for c in df.select_dtypes(include=['object']).columns:\n",
    "    df[c] = df[c].astype(str).str.strip()\n",
    "\n",
    "# Convert SeniorCitizen (0/1) to int (it's numeric already in many versions)\n",
    "if 'SeniorCitizen' in df.columns:\n",
    "    df['SeniorCitizen'] = df['SeniorCitizen'].astype(int)\n",
    "\n",
    "# Drop customerID if present — not a feature\n",
    "if 'customerID' in df.columns:\n",
    "    df = df.drop(columns=['customerID'])\n",
    "\n",
    "print('Dtypes after cleanup:')\n",
    "print(df.dtypes)\n",
    "\n",
    "# Identify categorical columns\n",
    "cat_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "print('Categorical columns (to encode):', cat_cols)\n",
    "print('Numeric columns:', num_cols)\n",
    "\n",
    "# One-hot encode categorical variables using pandas.get_dummies\n",
    "# For modeling later we often drop one level to avoid collinearity; keep all here for interpretability, or set drop_first=True if desired.\n",
    "df_encoded = pd.get_dummies(df, columns=cat_cols, drop_first=False)\n",
    "print('Shape before encoding:', df.shape)\n",
    "print('Shape after encoding:', df_encoded.shape)\n",
    "\n",
    "# Show a few columns to confirm encoding\n",
    "df_encoded.iloc[:, :30].head()\n",
    "\n",
    "# Ensure output directory exists and save cleaned dataset\n",
    "out_dir = Path('..') / 'data'\n",
    "out_dir.mkdir(exist_ok=True)\n",
    "out_path = out_dir / 'cleaned_telco_churn.csv'\n",
    "df_encoded.to_csv(out_path, index=False)\n",
    "print('Saved cleaned dataset to', out_path)\n",
    "print('Final dataframe shape:', df_encoded.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cf2c171",
   "metadata": {},
   "source": [
    "## Notes & Next Steps\n",
    "\n",
    "- This notebook completes Step 1: cleaning and basic encoding. The cleaned CSV `data/cleaned_telco_churn.csv` is ready for feature engineering and model building.\n",
    "- Next notebook will perform feature engineering and train baseline models (logistic regression / tree) and produce baseline metrics.\n",
    "- Later we will add explainability (SHAP/LIME) to show drivers of churn for business stakeholders.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
